{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "\n",
    "import analysis.images as im\n",
    "import modules.numpy_funcs as nf\n",
    "import modules.point_processing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = os.path.join('data', 'kinect', 'labelled_trials')\n",
    "\n",
    "best_pos_dir = os.path.join('data', 'kinect', 'best_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_trial_names = os.listdir(load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_part_grayscale = OrderedDict({'HEAD': 105,\n",
    "                       'L_HIP': 93,\n",
    "                       'R_HIP': 40,\n",
    "                       'L_THIGH': 133, \n",
    "                       'R_THIGH': 240,\n",
    "                       'L_KNEE': 52,\n",
    "                       'R_KNEE': 111,\n",
    "                       'L_CALF': 36,\n",
    "                       'R_CALF': 37,\n",
    "                       'L_FOOT': 135,\n",
    "                       'R_FOOT': 76,\n",
    "                      })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pos_dir = os.path.join('data', 'kinect', 'best_pos')\n",
    "\n",
    "\n",
    "# Camera calibration parameters\n",
    "x_res, y_res = 565, 430\n",
    "f_xz, f_yz = 1.11146664619446, 0.833599984645844\n",
    "\n",
    "\n",
    "pattern = re.compile(r'(\\d+)\\.png')\n",
    "\n",
    "for trial_name in labelled_trial_names[:1]:\n",
    "    \n",
    "    # Best positions selected by our method\n",
    "    df_best_pos = pd.read_pickle(os.path.join(best_pos_dir, trial_name + '.pkl'))\n",
    "    \n",
    "    label_dir = os.path.join(load_dir, trial_name, 'label')\n",
    "    depth_dir = os.path.join(load_dir, trial_name, 'depth16bit')\n",
    "\n",
    "    df_estimated = pd.read_pickle(os.path.join(best_pos_dir, trial_name + '.pkl'))\n",
    "    \n",
    "    label_paths = sorted(glob.glob(os.path.join(label_dir, '*.png')))\n",
    "    depth_paths = sorted(glob.glob(os.path.join(depth_dir, '*.png')))\n",
    "    \n",
    "    depth_filenames = [os.path.basename(x) for x in depth_paths]\n",
    "    frames = [int(re.search(pattern, x).group(1)) for x in depth_filenames]\n",
    "    \n",
    "    for i, frame in enumerate(frames):\n",
    "\n",
    "        \n",
    "        label_path, depth_path = label_paths[i], depth_paths[i]\n",
    "                        \n",
    "        label_image = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "        depth_image = cv2.imread(depth_path, cv2.IMREAD_ANYDEPTH)\n",
    "        \n",
    "        binary_image = label_image == body_part_grayscale['HEAD']\n",
    "        \n",
    "        if np.any(binary_image):\n",
    "        \n",
    "            y, x = np.round(center_of_mass(binary_image)).astype(int)\n",
    "            z = depth_image[y, x] / 10  # Convert mm to cm\n",
    "            \n",
    "            point_real = im.image_to_real([x, y, z], x_res, y_res, f_xz, f_yz)\n",
    "            \n",
    "                \n",
    "        if frame == 295:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_filenames = [os.path.basename(x) for x in label_paths]\n",
    "\n",
    "depth_frames = [int(re.search(pattern, x).group(1)) for x in depth_filenames]\n",
    "label_frames = [int(re.search(pattern, x).group(1)) for x in label_filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = body_part_grayscale.values()\n",
    "centroids = np.array([center_of_mass(label_image == label) for label in labels])\n",
    "\n",
    "# Round to nearest integer so that image can be indexed\n",
    "centroid_coords = np.round(centroids).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = depth_image[centroid_coords[:, 0], centroid_coords[:, 1]] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points in image space, in form (x, y, z)\n",
    "points_image = np.column_stack((np.fliplr(centroid_coords), depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to real coordinates\n",
    "points_real = np.apply_along_axis(im.image_to_real, 1, points_image, \n",
    "                                  x_res, y_res, f_xz, f_yz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_types = ['HEAD', 'HIP', 'THIGH', 'KNEE', 'CALF', 'FOOT']\n",
    "\n",
    "part_names, part_labels = zip(*body_part_grayscale.items())\n",
    "\n",
    "order_l = ['L_' + x if x != 'HEAD' else x for x in part_types ]\n",
    "order_r = ['R_' + x if x != 'HEAD' else x for x in part_types ]\n",
    "\n",
    "index_l = nf.find_indices(part_names, order_l)\n",
    "index_r = nf.find_indices(part_names, order_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.88827535, 13.3901949 , 20.21741358, 20.4333323 , 22.61615409])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.consecutive_dist(points_real[index_l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71.14739045, 20.05095822, 16.06476869, 21.02758158, 23.66292628])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.consecutive_dist(points_real[index_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.imshow(depth_image)\n",
    "plt.scatter(points_image[:, 0], points_image[:, 1], \n",
    "            c='w', edgecolor='k')\n",
    "\n",
    "plt.title('Frame {}'.format(frame))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:depth_gait_env]",
   "language": "python",
   "name": "conda-env-depth_gait_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
